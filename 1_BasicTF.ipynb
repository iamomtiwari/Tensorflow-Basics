{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhpQK8AihbzjVfahCMol9D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamomtiwari/Tensorflow-Basics/blob/main/BasicTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4SLhEcu_Wd19"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant([[1,2],[3,4]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENDTw-pnYI0D",
        "outputId": "22ecbf72-9fa3-4e59-addc-3f4797324b13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[1, 2],\n",
              "       [3, 4]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant([[1,2,3],[4,5,6],[6,7,8]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwWuICL0YTqn",
        "outputId": "2d0e1298-ea3d-4d36-cbc8-9c713c3fc1e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6],\n",
              "       [6, 7, 8]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how to create matrix in tensorflow. The idea here is to make constant and then give array for 3 rows."
      ],
      "metadata": {
        "id": "mnUAfmMfYvOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.zeros((3,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lQVHqRGYcl2",
        "outputId": "e62799bd-f6c3-442c-8f60-fba7d293c1cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how to create a zero matrix by defining zeros abd the shape of matrix."
      ],
      "metadata": {
        "id": "ySETW3-EYujh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.zeros((2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxM_5DwJYq4A",
        "outputId": "1f79c9ce-e6b2-47c8-bd85-258382a2c132"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "lB-qOwrkZK4v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt2KIBzjZdkg",
        "outputId": "10f76f31-f112-468e-b02b-262ff6e80d2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape(-1,28*28).astype(\"float32\")/255\n",
        "x_test=x_test.reshape(-1,28*28).astype(\"float32\")/255"
      ],
      "metadata": {
        "id": "sQXXXv1iZnP1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " x_train / x_test\n",
        "These are numpy arrays containing image data.\n",
        "\n",
        "For MNIST, each image is 28x28 pixels in grayscale, so initially, each image has a shape of (28, 28) and the dataset has shape (60000, 28, 28) for training and (10000, 28, 28) for test.\n",
        "\n",
        "ğŸ”¹ .reshape(-1, 28*28)\n",
        "This reshapes the image data from 2D (28x28) into 1D (784).\n",
        "\n",
        "-1 automatically infers the number of samples (like 60000 for training or 10000 for testing).\n",
        "\n",
        "So it converts x_train from shape (60000, 28, 28) â†’ (60000, 784).\n",
        "\n",
        "This is done because many neural networks expect flat input vectors, not 2D image matrices.\n",
        "\n",
        "ğŸ”¹ .astype(\"float32\")\n",
        "Converts the data type to float32 (from uint8).\n",
        "\n",
        "Original MNIST pixel values are integers between 0 to 255 (since it's grayscale).\n",
        "\n",
        "Converting to float allows for decimal precision, which is required for neural networks.\n",
        "\n",
        "ğŸ”¹ / 255\n",
        "Normalizes the pixel values to a range of 0 to 1.\n",
        "\n",
        "This helps the neural network train faster and more accurately, as large input values can lead to unstable training.\n",
        "\n",
        "âœ… Summary of What It Does:\n",
        "Flattens each MNIST image from 28x28 to 784, converts it to float32, and normalizes the pixel values from 0â€“255 to 0â€“1."
      ],
      "metadata": {
        "id": "uInrNQyjaU5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential(\n",
        "    [\n",
        "        #first is input of size 28x28\n",
        "        #keras.Input(shape=(28*28)),\n",
        "        layers.Dense(512,input_dim=28*28,activation=\"relu\"),\n",
        "        layers.Dense(256,activation=\"relu\"),\n",
        "        layers.Dense(10,activation=\"softmax\"),\n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irq0255QaWTd",
        "outputId": "9b5ec47f-1d2a-4f01-fc39-64d54d336459"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### âœ… **Full Model Code:**\n",
        "\n",
        "```python\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, input_dim=28*28, activation=\"relu\"),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”· `keras.Sequential([...])`\n",
        "\n",
        "* This means you're building a **feed-forward neural network**, layer by layer.\n",
        "* **Sequential** is used when each layer feeds directly into the next oneâ€”no branching or merging.\n",
        "* This is perfect for a basic classification model like MNIST.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **First Layer:**\n",
        "\n",
        "```python\n",
        "layers.Dense(512, input_dim=28*28, activation=\"relu\")\n",
        "```\n",
        "\n",
        "* **`Dense(512)`**: This creates a fully connected (dense) layer with **512 neurons**.\n",
        "* **`input_dim=28*28`**: Each input is a flattened image of size **784** (since 28Ã—28 = 784).\n",
        "* **`activation=\"relu\"`**: The **ReLU** activation adds non-linearity. It replaces negative values with 0.\n",
        "\n",
        "ğŸ“Œ Think of this as the first processing layer that takes all the 784 pixel values and learns 512 useful patterns/features from them.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Second Layer:**\n",
        "\n",
        "```python\n",
        "layers.Dense(256, activation=\"relu\")\n",
        "```\n",
        "\n",
        "* A dense layer with **256 neurons**.\n",
        "* It takes the 512 features from the previous layer and learns 256 more abstract patterns.\n",
        "* **ReLU** is again used to introduce non-linearity.\n",
        "\n",
        "ğŸ“Œ This deepens the learningâ€”more layers allow the network to learn more complex relationships.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Output Layer:**\n",
        "\n",
        "```python\n",
        "layers.Dense(10, activation=\"softmax\")\n",
        "```\n",
        "\n",
        "* This is the **output layer**, with **10 neurons** (since MNIST has **10 classes**, digits 0â€“9).\n",
        "* **`activation=\"softmax\"`**: Converts raw output scores into **probabilities** that sum to 1.\n",
        "\n",
        "ğŸ“Œ This layer tells you **which digit (0â€“9)** the model thinks the image represents, with probabilities.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… **Summary in Simple Terms:**\n",
        "\n",
        "* Input: Flattened image of **784 pixels**.\n",
        "* First Layer: Learns **512 features** from input using ReLU.\n",
        "* Second Layer: Refines that into **256 features**, again using ReLU.\n",
        "* Output Layer: Gives **probabilities for each digit (0â€“9)** using softmax.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ljqWDMThbkBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model=Sequential()\n",
        "model.add(Dense(512,input_dim=28*28,activation=\"relu\"))\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(Dense(10,activation=\"softmax\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMQsuKXCbbKt",
        "outputId": "7688cbb3-b031-4811-8693-ae28c86b6972"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step-by-Step Explanation:\n",
        "1ï¸âƒ£ model = Sequential()\n",
        "This creates an empty neural network model.\n",
        "\n",
        "You're going to add layers to this model in sequence, one after another.\n",
        "\n",
        "2ï¸âƒ£ model.add(Dense(512, input_dim=28*28, activation=\"relu\"))\n",
        "Adds the first hidden layer with:\n",
        "\n",
        "512 neurons.\n",
        "\n",
        "input_dim=28*28 â†’ accepts 784 input features (a flattened 28x28 MNIST image).\n",
        "\n",
        "activation=\"relu\" â†’ applies the ReLU (Rectified Linear Unit) function to introduce non-linearity.\n",
        "\n",
        "3ï¸âƒ£ model.add(Dense(256, activation=\"relu\"))\n",
        "Adds a second hidden layer with:\n",
        "\n",
        "256 neurons.\n",
        "\n",
        "No need to specify input_dim here because it automatically takes input from the previous layer.\n",
        "\n",
        "activation=\"relu\" â†’ again uses ReLU to help model learn complex features.\n",
        "\n",
        "4ï¸âƒ£ model.add(Dense(10, activation=\"softmax\"))\n",
        "Adds the output layer:\n",
        "\n",
        "10 neurons â†’ one for each MNIST class (digits 0 through 9).\n",
        "\n",
        "activation=\"softmax\" â†’ converts outputs into probabilities that sum to 1.\n",
        "\n",
        "ğŸ“Œ What This Model Does:\n",
        "It builds a neural network for digit classification (0â€“9) using:\n",
        "\n",
        "Input: Flattened 784-dimensional vectors.\n",
        "\n",
        "Hidden Layers: Two dense layers to learn features (512 â†’ 256).\n",
        "\n",
        "Output: 10-class softmax for digit prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "QaHyZUxXcfnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),#by default logits is fasle\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "rmWrw3-JcYhG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£ loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "You're using SparseCategoricalCrossentropy as your loss function.\n",
        "\n",
        "It is used when:\n",
        "\n",
        "You have integer-encoded labels (like 0, 1, 2,..., 9 for MNIST).\n",
        "\n",
        "Your model output uses softmax (i.e., from_logits=False).\n",
        "\n",
        "ğŸ”¸ If you had used activation=None in the output layer, then you'd set from_logits=True.\n",
        "\n",
        "2ï¸âƒ£ optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
        "This sets the optimizer to Adam, a very effective and commonly used optimizer.\n",
        "\n",
        "learning_rate=0.001 is a standard starting valueâ€”this controls how fast your model learns.\n",
        "\n",
        "3ï¸âƒ£ metrics=[\"accuracy\"]\n",
        "This tells Keras to display accuracy during training and evaluation.\n",
        "\n",
        "Accuracy is appropriate for classification problems like MNIST.\n",
        "\n",
        "âœ… Summary:\n",
        "Loss: SparseCategoricalCrossentropy â†’ For integer labels + softmax output.\n",
        "\n",
        "Optimizer: Adam with LR = 0.001.\n",
        "\n",
        "Metric: Accuracy to monitor how well the model is lear"
      ],
      "metadata": {
        "id": "zQ5-Q1hDdAJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… What Are **Logits**?\n",
        "\n",
        "* **Logits** are the **raw, unnormalized output scores** from the last layer of your neural network **before applying softmax**.\n",
        "* For example, your model might output something like:\n",
        "\n",
        "  ```python\n",
        "  [3.2, 1.1, -2.4, 0.7, ..., 4.8]  # 10 values for MNIST\n",
        "  ```\n",
        "* These values are called **logits**.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… What Does `from_logits=False` Mean?\n",
        "\n",
        "When you use:\n",
        "\n",
        "```python\n",
        "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
        "```\n",
        "\n",
        "You're telling Keras:\n",
        "\n",
        "> â€œ**My model already applied softmax**, so the output is a **probability distribution**. Don't apply softmax again.â€\n",
        "\n",
        "In your model, the output layer is:\n",
        "\n",
        "```python\n",
        "Dense(10, activation=\"softmax\")\n",
        "```\n",
        "\n",
        "So the softmax is **already applied** inside the model. Hence, `from_logits=False` is correct.\n",
        "\n",
        "---\n",
        "\n",
        "## â— What If `from_logits=True` But You Use Softmax in the Model?\n",
        "\n",
        "That would be a **mistake**.\n",
        "\n",
        "* If you use `from_logits=True`, the loss function **expects raw logits** (i.e., no softmax).\n",
        "* But if your model **already applied softmax**, then softmax would get applied **again internally** during loss computation.\n",
        "* This results in **double-softmax**, which will mess up your gradients and training. Your model may **fail to learn**.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Correct Pairings:\n",
        "\n",
        "| Model Output Activation | Loss Setting                  | Explanation                      |\n",
        "| ----------------------- | ----------------------------- | -------------------------------- |\n",
        "| `activation=\"softmax\"`  | `from_logits=False` âœ…         | Already softmaxed, no reapply.   |\n",
        "| `activation=None`       | `from_logits=True` âœ…          | Raw logits, softmax inside loss. |\n",
        "| `activation=\"softmax\"`  | `from_logits=True` âŒ (Wrong)  | Double softmax â€” will break it.  |\n",
        "| `activation=None`       | `from_logits=False` âŒ (Wrong) | No softmax applied at all.       |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ” Summary:\n",
        "\n",
        "* **Logits** = raw scores before softmax.\n",
        "* `from_logits=False` â†’ use this when your model ends in `softmax`.\n",
        "* `from_logits=True` â†’ use this when your model ends in **no activation** (i.e., raw output).\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FIcVYbT6dX5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "8nU4HrFKdAA1",
        "outputId": "0d74d89e-028e-4233-d78e-d390e8990c51"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m401,920\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m131,328\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m2,570\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=32,epochs=5,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntr38u3ndhGD",
        "outputId": "db8c14a1-6c78-406f-8e93-1f1257140b3e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.9043 - loss: 0.3177\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9756 - loss: 0.0791\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.0518\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0352\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9912 - loss: 0.0263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d1e28730c10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=32,epochs=5,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5m1tvdNd4w7",
        "outputId": "e91dfb63-70f0-4754-8115-1eb03ce87373"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9915 - loss: 0.0253\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0196\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0152\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.0164\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0139\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d1e2876ac50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x_test[0].reshape(1,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT6AXrJPeE8t",
        "outputId": "0e9d9836-429f-4039-8697-1e73c33bd88d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2543754e-17, 5.9871968e-11, 9.8572425e-18, 1.4730708e-13,\n",
              "        7.1460714e-14, 9.7226511e-18, 4.7434740e-16, 1.0000000e+00,\n",
              "        9.4799309e-13, 1.3828294e-10]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£ x_test[0]\n",
        "Picks the first test image from your x_test dataset.\n",
        "\n",
        "Originally, x_test[0] has shape (784,) (since you've flattened the 28x28 image earlier).\n",
        "\n",
        "2ï¸âƒ£ .reshape(1, -1)\n",
        "This reshapes the image from shape (784,) to (1, 784).\n",
        "\n",
        "Why? Because:\n",
        "\n",
        "Keras models expect a batch of samples as input, even if it's only 1 sample.\n",
        "\n",
        "Shape (1, 784) = 1 image, 784 features.\n",
        "\n",
        "3ï¸âƒ£ model.predict(...)\n",
        "This sends the reshaped image through your trained neural network.\n",
        "\n",
        "The output will be a 1x10 vector like:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "[[0.01, 0.02, 0.85, 0.03, ..., 0.01]]\n",
        "Each number is the predicted probability for digits 0 through 9.\n",
        "\n",
        "In this case, it thinks the image is most likely a â€˜2â€™ because 0.85 is the highest value at index 2.\n",
        "\n"
      ],
      "metadata": {
        "id": "e174HgAqfmC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=model.predict(x_test[0].reshape(1,-1))\n",
        "np.argmax(prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzsObYlwfm2D",
        "outputId": "af4b487a-5011-498d-ae18-e8a6fdf89a99"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(7)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”· Step-by-Step Explanation:\n",
        "1ï¸âƒ£ x_test[0]\n",
        "This selects the first image from your test dataset.\n",
        "\n",
        "Shape: (784,) because MNIST images were flattened from 28Ã—28 to 1D.\n",
        "\n",
        "2ï¸âƒ£ .reshape(1, -1)\n",
        "Reshapes the 1D array to 2D: from (784,) to (1, 784).\n",
        "\n",
        "The model expects batch input, even for just 1 image.\n",
        "\n",
        "-1 is a flexible dimensionâ€”it means \"infer automatically\" (in this case, 784 features).\n",
        "\n",
        "3ï¸âƒ£ model.predict(...)\n",
        "Feeds the reshaped image into the model.\n",
        "\n",
        "Returns a probability distribution over the 10 possible digit classes.\n",
        "\n",
        "For example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "prediction = model.predict(...)\n",
        "# prediction might be:\n",
        "[[0.01, 0.03, 0.85, 0.02, 0.01, 0.01, 0.02, 0.02, 0.02, 0.01]]\n",
        "This is a 1x10 array:\n",
        "\n",
        "Each value is the modelâ€™s confidence that the input image is digit 0, 1, ..., 9.\n",
        "\n",
        "In this case, 0.85 at index 2 â†’ model thinks it's most likely a \"2\".\n",
        "\n",
        "4ï¸âƒ£ prediction[0]\n",
        "Accesses the first row (only one sample was predicted).\n",
        "\n",
        "This gives the actual 10-class probability array.\n",
        "\n",
        "5ï¸âƒ£ np.argmax(prediction[0])\n",
        "Finds the index of the highest probability.\n",
        "\n",
        "That index corresponds to the predicted digit."
      ],
      "metadata": {
        "id": "5WqHKawMgaY5"
      }
    }
  ]
}
